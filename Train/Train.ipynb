{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Umer\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Umer\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.10.0 and strictly below 2.13.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.7.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "import keras.layers as L\n",
    "from keras import optimizers, losses, metrics, Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential, load_model\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow_model_optimization as tfmot\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['False' 'True']\n",
      "2\n",
      "1810\n",
      "(1810, 1000, 1, 1)\n",
      "(1810, 2)\n"
     ]
    }
   ],
   "source": [
    "inputPath = r\"C:\\Rotated Equal Data\"\n",
    "inputPath = r\"D:\\Programing\\Projects\\ESP32-TFLite-Knock-Detector\\Data Collection\\Data\\Equal Data\"\n",
    "\n",
    "commands = np.array(tf.io.gfile.listdir(str(inputPath)))\n",
    "print(commands)\n",
    "N_CLASSES = len(commands)\n",
    "print(N_CLASSES)\n",
    "\n",
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]\n",
    "\n",
    "filesArray = []\n",
    "for path, subdirs, files in os.walk(inputPath):\n",
    "    for name in files:\n",
    "        filesArray.append(os.path.join(path + \"\\\\\", name))\n",
    "print(len(filesArray))\n",
    "\n",
    "\n",
    "\n",
    "#for i in filesArray:\n",
    "    #print(i)\n",
    "    \n",
    "max_length = 1000\n",
    "df = []\n",
    "labels = []\n",
    "for filename in filesArray:\n",
    "    data = np.loadtxt(filename, dtype=np.float32)\n",
    "    \n",
    "    data = data/2 #Normalise\n",
    "    data = abs(data)\n",
    "\n",
    "    if len(data) < max_length:\n",
    "        # pad the time series with zeros to a length of 1000\n",
    "        data = np.pad(data, [(0, max_length - len(data)), (0, 0)], mode='constant')\n",
    "    elif len(data) > max_length:\n",
    "        # truncate the time series to a length of 1000\n",
    "        data = data[:max_length, :]\n",
    "    a = filename.split(\"\\\\\")[-2]\n",
    "    if a == \"True\":\n",
    "        label = [1,0]\n",
    "    else:\n",
    "        label = [0,1]\n",
    "    labels.append(label)\n",
    "\n",
    "    data = np.expand_dims(data, axis=-1)\n",
    "    data = np.expand_dims(data, axis=-1)\n",
    "    df.append(data)\n",
    "\n",
    "df_array = np.array(df)\n",
    "labels_array = np.array(labels)\n",
    "\n",
    "df_array, labels_array = unison_shuffled_copies(df_array, labels_array)\n",
    "\n",
    "df_array, labels_array = unison_shuffled_copies(df_array, labels_array)\n",
    "\n",
    "print(df_array.shape)\n",
    "print(labels_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_array[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_16 (Conv2D)          (None, 901, 1, 8)         808       \n",
      "                                                                 \n",
      " average_pooling2d_16 (Avera  (None, 450, 1, 8)        0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 436, 1, 16)        1936      \n",
      "                                                                 \n",
      " average_pooling2d_17 (Avera  (None, 218, 1, 16)       0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 214, 1, 16)        1296      \n",
      "                                                                 \n",
      " average_pooling2d_18 (Avera  (None, 107, 1, 16)       0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 105, 1, 16)        784       \n",
      "                                                                 \n",
      " average_pooling2d_19 (Avera  (None, 52, 1, 16)        0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 832)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 32)                26656     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,546\n",
      "Trainable params: 31,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/3\n",
      "68554/68554 [==============================] - 186s 3ms/step - loss: 0.2032 - categorical_accuracy: 0.9164 - val_loss: 0.1024 - val_categorical_accuracy: 0.9655 - lr: 0.0010\n",
      "Epoch 2/3\n",
      "68554/68554 [==============================] - 189s 3ms/step - loss: 0.0907 - categorical_accuracy: 0.9687 - val_loss: 0.0740 - val_categorical_accuracy: 0.9747 - lr: 0.0010\n",
      "Epoch 3/3\n",
      "68554/68554 [==============================] - 189s 3ms/step - loss: 0.0725 - categorical_accuracy: 0.9763 - val_loss: 0.0813 - val_categorical_accuracy: 0.9734 - lr: 0.0010\n",
      "Epoch 4/11\n",
      "5428/5428 [==============================] - 75s 14ms/step - loss: 0.0463 - categorical_accuracy: 0.9849 - val_loss: 0.0370 - val_categorical_accuracy: 0.9881 - lr: 0.0010\n",
      "Epoch 5/11\n",
      "5428/5428 [==============================] - 67s 12ms/step - loss: 0.0273 - categorical_accuracy: 0.9907 - val_loss: 0.0284 - val_categorical_accuracy: 0.9902 - lr: 0.0010\n",
      "tf.Tensor(0.001, shape=(), dtype=float32)\n",
      "Epoch 6/11\n",
      "5428/5428 [==============================] - 66s 12ms/step - loss: 0.0173 - categorical_accuracy: 0.9944 - val_loss: 0.0205 - val_categorical_accuracy: 0.9918 - lr: 0.0010\n",
      "tf.Tensor(0.0009801987, shape=(), dtype=float32)\n",
      "Epoch 7/11\n",
      "5428/5428 [==============================] - 66s 12ms/step - loss: 0.0115 - categorical_accuracy: 0.9964 - val_loss: 0.0320 - val_categorical_accuracy: 0.9894 - lr: 9.8020e-04\n",
      "tf.Tensor(0.0009607895, shape=(), dtype=float32)\n",
      "Epoch 8/11\n",
      "5428/5428 [==============================] - 67s 12ms/step - loss: 0.0094 - categorical_accuracy: 0.9970 - val_loss: 0.0096 - val_categorical_accuracy: 0.9972 - lr: 9.6079e-04\n",
      "tf.Tensor(0.00094176456, shape=(), dtype=float32)\n",
      "Epoch 9/11\n",
      "5428/5428 [==============================] - 65s 12ms/step - loss: 0.0069 - categorical_accuracy: 0.9979 - val_loss: 0.0113 - val_categorical_accuracy: 0.9965 - lr: 9.4176e-04\n",
      "tf.Tensor(0.00092311634, shape=(), dtype=float32)\n",
      "Epoch 10/11\n",
      "3321/5428 [=================>............] - ETA: 25s - loss: 0.0055 - categorical_accuracy: 0.9984"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 61\u001b[0m\n\u001b[0;32m     56\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(learning_rate \u001b[39m=\u001b[39m \u001b[39m0.001\u001b[39m),\n\u001b[0;32m     57\u001b[0m               loss\u001b[39m=\u001b[39mlosses\u001b[39m.\u001b[39mCategoricalCrossentropy(),\n\u001b[0;32m     58\u001b[0m               metrics\u001b[39m=\u001b[39m[metrics\u001b[39m.\u001b[39mCategoricalAccuracy()])\n\u001b[0;32m     60\u001b[0m new_epochs \u001b[39m=\u001b[39m \u001b[39m8\u001b[39m\n\u001b[1;32m---> 61\u001b[0m model\u001b[39m.\u001b[39;49mfit(df_array, labels_array, shuffle\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,  initial_epoch\u001b[39m=\u001b[39;49mtotal_epochs, epochs\u001b[39m=\u001b[39;49mtotal_epochs\u001b[39m+\u001b[39;49mnew_epochs, validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.05\u001b[39;49m, batch_size \u001b[39m=\u001b[39;49m \u001b[39m32\u001b[39;49m, callbacks\u001b[39m=\u001b[39;49m[tensorboard_callback,lr_scheduler])\n\u001b[0;32m     62\u001b[0m total_epochs \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m new_epochs\n\u001b[0;32m     64\u001b[0m model\u001b[39m.\u001b[39mevaluate(df_array, labels_array, batch_size\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py:1216\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1209\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1210\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1211\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1212\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1213\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1214\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1215\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1216\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1217\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1218\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py:910\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    907\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    909\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 910\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    912\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    913\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py:942\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    939\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    940\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    941\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 942\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    943\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    944\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    945\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:3130\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3127\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   3128\u001b[0m   (graph_function,\n\u001b[0;32m   3129\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3130\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   3131\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:1959\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1955\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1956\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1957\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1958\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1959\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1960\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1961\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1962\u001b[0m     args,\n\u001b[0;32m   1963\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1964\u001b[0m     executing_eagerly)\n\u001b[0;32m   1965\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:598\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    597\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 598\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    599\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    600\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    601\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    602\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    603\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    604\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    605\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    606\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    607\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    610\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    611\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py:58\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     57\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 58\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     59\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     61\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "# Define the log directory for TensorBoard\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "def lr_schedule(epoch, lr):\n",
    "    if epoch < 5:\n",
    "        return lr\n",
    "    else:\n",
    "        print(0.001 * tf.math.exp(-0.02*((epoch-5))))\n",
    "        return 0.001 * tf.math.exp(-0.02*((epoch-5)))\n",
    "\n",
    "# Define the TensorBoard callback\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_schedule)\n",
    "\n",
    "    \n",
    "total_epochs = 0\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(L.Input(shape=(1000,1, 1)))\n",
    "\n",
    "# Block 1\n",
    "model.add(L.Conv2D(8, (100, 1), activation='relu'))\n",
    "model.add(L.AveragePooling2D((2, 1), strides=(2, 1)))\n",
    "\n",
    "# Block 2\n",
    "model.add(L.Conv2D(16, (15, 1), activation='relu'))\n",
    "model.add(L.AveragePooling2D((2, 1)))\n",
    "\n",
    "# Block 3\n",
    "model.add(L.Conv2D(16, (5, 1), activation='relu'))\n",
    "model.add(L.AveragePooling2D((2, 1)))\n",
    "\n",
    "# Block 4\n",
    "model.add(L.Conv2D(16, (3, 1), activation='relu'))\n",
    "model.add(L.AveragePooling2D((2, 1)))\n",
    "\n",
    "# Fully connected L\n",
    "model.add(L.Flatten())\n",
    "model.add(L.Dense(32, activation='relu'))\n",
    "model.add(L.Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=tf.optimizers.SGD(learning_rate = 0.001, momentum=0.9),\n",
    "              loss=losses.CategoricalCrossentropy(),\n",
    "              metrics=[metrics.CategoricalAccuracy()])\n",
    "\n",
    "# model.build((235, 4001, 1))\n",
    "print(model.summary())\n",
    "\n",
    "new_epochs = 3\n",
    "model.fit(df_array, labels_array, shuffle=1,  initial_epoch=total_epochs, epochs=total_epochs+new_epochs, validation_split=0.25, batch_size = 2, callbacks=[tensorboard_callback,lr_scheduler])\n",
    "total_epochs += new_epochs\n",
    "\n",
    "model.compile(optimizer=tf.optimizers.Adam(learning_rate = 0.001),\n",
    "              loss=losses.CategoricalCrossentropy(),\n",
    "              metrics=[metrics.CategoricalAccuracy()])\n",
    "\n",
    "new_epochs = 8\n",
    "model.fit(df_array, labels_array, shuffle=1,  initial_epoch=total_epochs, epochs=total_epochs+new_epochs, validation_split=0.05, batch_size = 32, callbacks=[tensorboard_callback,lr_scheduler])\n",
    "total_epochs += new_epochs\n",
    "\n",
    "model.evaluate(df_array, labels_array, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182810/182810 [==============================] - 163s 890us/step - loss: 0.0039 - categorical_accuracy: 0.9988\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.003925190772861242, 0.9988184571266174]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(df_array, labels_array, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.models.save_model(model, 'model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Umer\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow_model_optimization\\python\\core\\sparsity\\keras\\pruning_wrapper.py:212: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  mask = self.add_variable(\n",
      "C:\\Users\\Umer\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow_model_optimization\\python\\core\\sparsity\\keras\\pruning_wrapper.py:219: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  threshold = self.add_variable(\n",
      "C:\\Users\\Umer\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow_model_optimization\\python\\core\\sparsity\\keras\\pruning_wrapper.py:233: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  self.pruning_step = self.add_variable(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1072/1072 [==============================] - 57s 51ms/step - loss: 0.0034 - categorical_accuracy: 0.9990 - val_loss: 0.0039 - val_categorical_accuracy: 0.9988\n",
      "Epoch 2/20\n",
      "1072/1072 [==============================] - 55s 51ms/step - loss: 0.0029 - categorical_accuracy: 0.9992 - val_loss: 0.0034 - val_categorical_accuracy: 0.9989\n",
      "Epoch 3/20\n",
      "1072/1072 [==============================] - 53s 49ms/step - loss: 0.0026 - categorical_accuracy: 0.9993 - val_loss: 0.0031 - val_categorical_accuracy: 0.9991\n",
      "Epoch 4/20\n",
      "1072/1072 [==============================] - 53s 49ms/step - loss: 0.0024 - categorical_accuracy: 0.9994 - val_loss: 0.0029 - val_categorical_accuracy: 0.9992\n",
      "Epoch 5/20\n",
      "1072/1072 [==============================] - 53s 49ms/step - loss: 0.0022 - categorical_accuracy: 0.9995 - val_loss: 0.0027 - val_categorical_accuracy: 0.9993\n",
      "Epoch 6/20\n",
      "1072/1072 [==============================] - 53s 49ms/step - loss: 0.0021 - categorical_accuracy: 0.9995 - val_loss: 0.0026 - val_categorical_accuracy: 0.9993\n",
      "Epoch 7/20\n",
      "1072/1072 [==============================] - 53s 49ms/step - loss: 0.0020 - categorical_accuracy: 0.9995 - val_loss: 0.0024 - val_categorical_accuracy: 0.9993\n",
      "Epoch 8/20\n",
      "1072/1072 [==============================] - 53s 49ms/step - loss: 0.0019 - categorical_accuracy: 0.9996 - val_loss: 0.0024 - val_categorical_accuracy: 0.9994\n",
      "Epoch 9/20\n",
      "1072/1072 [==============================] - 53s 49ms/step - loss: 0.0018 - categorical_accuracy: 0.9996 - val_loss: 0.0023 - val_categorical_accuracy: 0.9994\n",
      "Epoch 10/20\n",
      "1072/1072 [==============================] - 53s 49ms/step - loss: 0.0018 - categorical_accuracy: 0.9996 - val_loss: 0.0022 - val_categorical_accuracy: 0.9995\n",
      "Epoch 11/20\n",
      "1072/1072 [==============================] - 53s 49ms/step - loss: 0.0017 - categorical_accuracy: 0.9996 - val_loss: 0.0021 - val_categorical_accuracy: 0.9995\n",
      "Epoch 12/20\n",
      "1072/1072 [==============================] - 53s 49ms/step - loss: 0.0017 - categorical_accuracy: 0.9996 - val_loss: 0.0021 - val_categorical_accuracy: 0.9995\n",
      "Epoch 13/20\n",
      "1072/1072 [==============================] - 53s 49ms/step - loss: 0.0016 - categorical_accuracy: 0.9996 - val_loss: 0.0021 - val_categorical_accuracy: 0.9995\n",
      "Epoch 14/20\n",
      "1072/1072 [==============================] - 53s 50ms/step - loss: 0.0016 - categorical_accuracy: 0.9997 - val_loss: 0.0020 - val_categorical_accuracy: 0.9995\n",
      "Epoch 15/20\n",
      "1072/1072 [==============================] - 53s 49ms/step - loss: 0.0016 - categorical_accuracy: 0.9997 - val_loss: 0.0020 - val_categorical_accuracy: 0.9996\n",
      "Epoch 16/20\n",
      "1072/1072 [==============================] - 53s 49ms/step - loss: 0.0015 - categorical_accuracy: 0.9997 - val_loss: 0.0019 - val_categorical_accuracy: 0.9995\n",
      "Epoch 17/20\n",
      "1072/1072 [==============================] - 53s 49ms/step - loss: 0.0015 - categorical_accuracy: 0.9997 - val_loss: 0.0019 - val_categorical_accuracy: 0.9995\n",
      "Epoch 18/20\n",
      "1072/1072 [==============================] - 53s 49ms/step - loss: 0.0015 - categorical_accuracy: 0.9997 - val_loss: 0.0019 - val_categorical_accuracy: 0.9996\n",
      "Epoch 19/20\n",
      "1072/1072 [==============================] - 53s 49ms/step - loss: 0.0015 - categorical_accuracy: 0.9997 - val_loss: 0.0018 - val_categorical_accuracy: 0.9996\n",
      "Epoch 20/20\n",
      "1072/1072 [==============================] - 53s 49ms/step - loss: 0.0014 - categorical_accuracy: 0.9997 - val_loss: 0.0018 - val_categorical_accuracy: 0.9996\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# Load your Keras model\n",
    "model = tf.keras.models.load_model('model.h5')\n",
    "\n",
    "# Define the pruning parameters\n",
    "pruning_schedule = tfmot.sparsity.keras.PolynomialDecay(\n",
    "    initial_sparsity=0.1,\n",
    "    final_sparsity=0.99,\n",
    "    begin_step=0,\n",
    "    end_step=19\n",
    ")\n",
    "\n",
    "# Define the pruning callback\n",
    "pruning_callbacks = [\n",
    "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "  tfmot.sparsity.keras.PruningSummaries(log_dir='/tmp')\n",
    "]\n",
    "\n",
    "# Create a pruned model\n",
    "pruned_model = tfmot.sparsity.keras.prune_low_magnitude(model, pruning_schedule=pruning_schedule)\n",
    "\n",
    "# Train the pruned model\n",
    "pruned_model.compile(optimizer=tf.optimizers.Adam(learning_rate= 0.000001),\n",
    "              loss=losses.CategoricalCrossentropy(),\n",
    "              metrics=[metrics.CategoricalAccuracy()])\n",
    "pruned_model.fit(df_array, labels_array, shuffle=1, epochs=20, validation_split=0.25, batch_size=128, callbacks=pruning_callbacks)\n",
    "\n",
    "# Remove the pruning wrappers from the model\n",
    "pruned_model = tfmot.sparsity.keras.strip_pruning(pruned_model)\n",
    "\n",
    "# Save the pruned model\n",
    "pruned_model.save('pruned_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# Load your Keras model\n",
    "pruned_model = tf.keras.models.load_model('pruned_model.h5')\n",
    "pruned_model.compile(optimizer=tf.optimizers.Adam(learning_rate= 0.0001),\n",
    "              loss=losses.CategoricalCrossentropy(),\n",
    "              metrics=[metrics.CategoricalAccuracy()])\n",
    "#pruned_model.evaluate(df_array, labels_array, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "######### NON QUANTIZED ############\n",
    "pruned_model = tf.keras.models.load_model(\"pruned_model.h5\")\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(pruned_model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Optimization option OPTIMIZE_FOR_SIZE is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n",
      "WARNING:absl:Optimization option OPTIMIZE_FOR_SIZE is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n",
      "WARNING:absl:Optimization option OPTIMIZE_FOR_SIZE is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n"
     ]
    }
   ],
   "source": [
    "######### QUANTIZED ############\n",
    "pruned_model = tf.keras.models.load_model(\"pruned_model.h5\")\n",
    "\n",
    "def representative_data_gen():\n",
    "    for input_value in df_array:\n",
    "        input_value = np.expand_dims(input_value, axis=0)\n",
    "        yield [input_value]\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(pruned_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT, tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "#converter.target_spec.supported_ops = [tf.float16]\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('model_quantized.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#interpreter = tf.lite.Interpreter(model_path=\"model.tflite\")\n",
    "interpreter = tf.lite.Interpreter(model_path=\"model_quantized.tflite\")\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensor scale: [0.00392157]\n",
      "Input tensor zero-point: [0]\n",
      "Output tensor scale: 0.00390625\n",
      "Output tensor zero-point: 0\n"
     ]
    }
   ],
   "source": [
    "# Get the input tensor details\n",
    "input_details = interpreter.get_input_details()\n",
    "input_tensor_index = input_details[0]['index']\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "\n",
    "# Get the scale and zero-point values from the input tensor\n",
    "input_tensor_scale = input_details[0]['quantization_parameters']['scales']\n",
    "input_tensor_zero_point = input_details[0]['quantization_parameters']['zero_points']\n",
    "\n",
    "output_tensor_scale = output_details[0]['quantization'][0]\n",
    "output_tensor_zero_point = output_details[0]['quantization'][1]\n",
    "\n",
    "print(\"Input tensor scale:\", input_tensor_scale)\n",
    "print(\"Input tensor zero-point:\", input_tensor_zero_point)\n",
    "\n",
    "print(\"Output tensor scale:\", output_tensor_scale)\n",
    "print(\"Output tensor zero-point:\", output_tensor_zero_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## For Quantized only ###################\n",
    "for j in range(len(df_array)):\n",
    "    for i in range(len(df_array[0])):\n",
    "        df_array[j][i][0] = int(df_array[j][i][0] / input_tensor_scale) + input_tensor_zero_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[129.]],\n",
       "\n",
       "       [[129.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[129.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[129.]],\n",
       "\n",
       "       [[129.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[129.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[128.]],\n",
       "\n",
       "       [[128.]],\n",
       "\n",
       "       [[219.]],\n",
       "\n",
       "       [[219.]],\n",
       "\n",
       "       [[ 98.]],\n",
       "\n",
       "       [[101.]],\n",
       "\n",
       "       [[101.]],\n",
       "\n",
       "       [[ 70.]],\n",
       "\n",
       "       [[ 70.]],\n",
       "\n",
       "       [[205.]],\n",
       "\n",
       "       [[205.]],\n",
       "\n",
       "       [[233.]],\n",
       "\n",
       "       [[138.]],\n",
       "\n",
       "       [[138.]],\n",
       "\n",
       "       [[153.]],\n",
       "\n",
       "       [[153.]],\n",
       "\n",
       "       [[209.]],\n",
       "\n",
       "       [[118.]],\n",
       "\n",
       "       [[118.]],\n",
       "\n",
       "       [[136.]],\n",
       "\n",
       "       [[136.]],\n",
       "\n",
       "       [[205.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[ 75.]],\n",
       "\n",
       "       [[ 75.]],\n",
       "\n",
       "       [[ 99.]],\n",
       "\n",
       "       [[ 99.]],\n",
       "\n",
       "       [[151.]],\n",
       "\n",
       "       [[159.]],\n",
       "\n",
       "       [[159.]],\n",
       "\n",
       "       [[118.]],\n",
       "\n",
       "       [[118.]],\n",
       "\n",
       "       [[113.]],\n",
       "\n",
       "       [[128.]],\n",
       "\n",
       "       [[128.]],\n",
       "\n",
       "       [[120.]],\n",
       "\n",
       "       [[120.]],\n",
       "\n",
       "       [[110.]],\n",
       "\n",
       "       [[110.]],\n",
       "\n",
       "       [[136.]],\n",
       "\n",
       "       [[152.]],\n",
       "\n",
       "       [[152.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[102.]],\n",
       "\n",
       "       [[104.]],\n",
       "\n",
       "       [[104.]],\n",
       "\n",
       "       [[112.]],\n",
       "\n",
       "       [[112.]],\n",
       "\n",
       "       [[117.]],\n",
       "\n",
       "       [[117.]],\n",
       "\n",
       "       [[126.]],\n",
       "\n",
       "       [[140.]],\n",
       "\n",
       "       [[140.]],\n",
       "\n",
       "       [[147.]],\n",
       "\n",
       "       [[147.]],\n",
       "\n",
       "       [[140.]],\n",
       "\n",
       "       [[129.]],\n",
       "\n",
       "       [[129.]],\n",
       "\n",
       "       [[137.]],\n",
       "\n",
       "       [[137.]],\n",
       "\n",
       "       [[156.]],\n",
       "\n",
       "       [[151.]],\n",
       "\n",
       "       [[151.]],\n",
       "\n",
       "       [[143.]],\n",
       "\n",
       "       [[143.]],\n",
       "\n",
       "       [[138.]],\n",
       "\n",
       "       [[138.]],\n",
       "\n",
       "       [[139.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[126.]],\n",
       "\n",
       "       [[126.]],\n",
       "\n",
       "       [[127.]],\n",
       "\n",
       "       [[124.]],\n",
       "\n",
       "       [[124.]],\n",
       "\n",
       "       [[114.]],\n",
       "\n",
       "       [[114.]],\n",
       "\n",
       "       [[112.]],\n",
       "\n",
       "       [[112.]],\n",
       "\n",
       "       [[125.]],\n",
       "\n",
       "       [[138.]],\n",
       "\n",
       "       [[138.]],\n",
       "\n",
       "       [[141.]],\n",
       "\n",
       "       [[141.]],\n",
       "\n",
       "       [[135.]],\n",
       "\n",
       "       [[129.]],\n",
       "\n",
       "       [[129.]],\n",
       "\n",
       "       [[125.]],\n",
       "\n",
       "       [[125.]],\n",
       "\n",
       "       [[120.]],\n",
       "\n",
       "       [[120.]],\n",
       "\n",
       "       [[124.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[129.]],\n",
       "\n",
       "       [[129.]],\n",
       "\n",
       "       [[124.]],\n",
       "\n",
       "       [[128.]],\n",
       "\n",
       "       [[128.]],\n",
       "\n",
       "       [[135.]],\n",
       "\n",
       "       [[135.]],\n",
       "\n",
       "       [[137.]],\n",
       "\n",
       "       [[137.]],\n",
       "\n",
       "       [[138.]],\n",
       "\n",
       "       [[140.]],\n",
       "\n",
       "       [[140.]],\n",
       "\n",
       "       [[138.]],\n",
       "\n",
       "       [[138.]],\n",
       "\n",
       "       [[135.]],\n",
       "\n",
       "       [[135.]],\n",
       "\n",
       "       [[135.]],\n",
       "\n",
       "       [[136.]],\n",
       "\n",
       "       [[136.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[125.]],\n",
       "\n",
       "       [[124.]],\n",
       "\n",
       "       [[124.]],\n",
       "\n",
       "       [[127.]],\n",
       "\n",
       "       [[127.]],\n",
       "\n",
       "       [[129.]],\n",
       "\n",
       "       [[129.]],\n",
       "\n",
       "       [[129.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[135.]],\n",
       "\n",
       "       [[136.]],\n",
       "\n",
       "       [[136.]],\n",
       "\n",
       "       [[133.]],\n",
       "\n",
       "       [[133.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[129.]],\n",
       "\n",
       "       [[127.]],\n",
       "\n",
       "       [[127.]],\n",
       "\n",
       "       [[126.]],\n",
       "\n",
       "       [[126.]],\n",
       "\n",
       "       [[125.]],\n",
       "\n",
       "       [[128.]],\n",
       "\n",
       "       [[128.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[134.]],\n",
       "\n",
       "       [[135.]],\n",
       "\n",
       "       [[135.]],\n",
       "\n",
       "       [[138.]],\n",
       "\n",
       "       [[138.]],\n",
       "\n",
       "       [[136.]],\n",
       "\n",
       "       [[133.]],\n",
       "\n",
       "       [[133.]],\n",
       "\n",
       "       [[133.]],\n",
       "\n",
       "       [[133.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[129.]],\n",
       "\n",
       "       [[129.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[128.]],\n",
       "\n",
       "       [[129.]],\n",
       "\n",
       "       [[129.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[129.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[127.]],\n",
       "\n",
       "       [[127.]],\n",
       "\n",
       "       [[127.]],\n",
       "\n",
       "       [[127.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[134.]],\n",
       "\n",
       "       [[134.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[128.]],\n",
       "\n",
       "       [[128.]],\n",
       "\n",
       "       [[129.]],\n",
       "\n",
       "       [[129.]],\n",
       "\n",
       "       [[129.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[133.]],\n",
       "\n",
       "       [[133.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[133.]],\n",
       "\n",
       "       [[133.]],\n",
       "\n",
       "       [[133.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[129.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[133.]],\n",
       "\n",
       "       [[133.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[129.]],\n",
       "\n",
       "       [[129.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[129.]],\n",
       "\n",
       "       [[129.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[133.]],\n",
       "\n",
       "       [[133.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[133.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[129.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[129.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[132.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[131.]],\n",
       "\n",
       "       [[130.]],\n",
       "\n",
       "       [[130.]]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_array[21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.00390625]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.9921875 0.0078125]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.97265625 0.02734375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.00390625]]\n",
      "Label: [0 1]  tflite model prediction: [[0.02734375 0.97265625]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.00390625 0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.76953125 0.23046875]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.0078125 0.9921875]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.00390625 0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.046875 0.953125]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.00390625]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.953125 0.046875]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.9921875 0.0078125]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.00390625]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.00390625 0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.02734375 0.97265625]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.984375 0.015625]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.00390625 0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.91796875 0.08203125]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.00390625]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.00390625 0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.97265625 0.02734375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.0078125 0.9921875]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.08203125 0.91796875]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.984375 0.015625]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.953125 0.046875]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.9921875 0.0078125]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.984375 0.015625]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.984375 0.015625]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.00390625]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.00390625]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.9921875 0.0078125]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.91796875 0.08203125]]\n",
      "Label: [1 0]  tflite model prediction: [[0.9921875 0.0078125]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.046875 0.953125]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.02734375 0.97265625]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.859375 0.140625]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.0078125 0.9921875]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.953125 0.046875]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.015625 0.984375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.76953125 0.23046875]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.00390625]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.0078125 0.9921875]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.015625 0.984375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.02734375 0.97265625]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.00390625]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.00390625 0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.953125 0.046875]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.76953125 0.23046875]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.984375 0.015625]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.00390625]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.953125 0.046875]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.015625 0.984375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.953125 0.046875]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.859375 0.140625]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.00390625]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.984375 0.015625]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.00390625 0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.953125 0.046875]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.9921875 0.0078125]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.046875 0.953125]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.00390625 0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.984375 0.015625]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.08203125 0.91796875]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.00390625]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n",
      "Label: [0 1]  tflite model prediction: [[0.         0.99609375]]\n",
      "Label: [1 0]  tflite model prediction: [[0.99609375 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "\n",
    "for i in range(len(df_array)):\n",
    "    interpreter.set_tensor(input_details[0]['index'], df_array[i:i+1].astype(np.uint8))\n",
    "    interpreter.invoke()\n",
    "    output = (interpreter.get_tensor(output_details[0]['index']) - output_tensor_zero_point)*output_tensor_scale\n",
    "    #origional = model.predict(df_array[i:i+1], verbose=0)\n",
    "        \n",
    "    print(f'Label: {labels_array[i]}  tflite model prediction: {output}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
